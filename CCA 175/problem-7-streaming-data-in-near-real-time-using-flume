*******
******* STEP 1 
*******
	***
	***  1
	***
	sqoop import \
	--connect jdbc:mysql://ms.itversity.com:3306/retail_db \
	--username _user --password _pwd --table orders \
	--target-dir /user/cloudera/problem7/prework --as-avrodatafile \
	--m 1


	***
	*** 2
	***
	$ mkdir flume-avro
	$ hdfs dfs -copyToLocal /user/cloudera/problem7/prework flume-avro
	$ mkdir flumeProblem7

	***
	*** 3
	***
	$ cd flumeProblem7
	$ vi flume_pb.conf

	----------------
	fa7.sources = r1
	fa7.sinks = k1
	fa7.channels = c1

	# Describe/configure the source
	fa7.sources.r1.type = avro
	fa7.sources.r1.bind = localhost
	fa7.sources.r1.port = 11112

	# Describe the sink
	fa7.sinks.k1.type = hdfs 
	fa7.sinks.k1.hdfs.path = /user/cloudera/problem7/sink

	# Use a channel which buffers events in memory
	fa7.channels.c1.type = jdbc

	# Bind the source and sink to the channel
	fa7.sources.r1.channels = c1
	fa7.sinks.k1.channel = c1
	-------------------
	:x

	***
	*** 4
	***

	$ flume-ng agent --n fa7 --f /home/cloudera/fumeProblem7/flume_pb.conf 

	$ flume-ng avro-client -H localhost -p 11112 -F /user/cloudera/problem7/prework

*******
******* STEP 2 
*******
	***
	***  1 - run start_logs
	***
    $ start_logs

	***
	***  2 - write a flume configuration such that the logs generated by start_logs are dumped into HDFS...
	***
	$ cd flumeProblem7
	$ vi flume_pb2.conf

	----------------
	fa7_2.sources = r1
	fa7_2.sinks = k1
	fa7_2.channels = c1

	# Describe/configure the source
	fa7_2.sources.r1.type = exec
	fa7_2.sources.r1.command = tail -F /opt/gen_logs/logs/access.log

	# Describe the sink
	fa7_2.sinks.k1.type = hdfs 
	fa7_2.sinks.k1.hdfs.path = /user/cloudera/problem7/step2

	# Use a channel which buffers events in memory
	fa7_2.channels.c1.type = memory 
	fa7_2.channels.c1.capacity = 1000
	fa7_2.channels.c1.transactionCapacity = 200

	# Bind the source and sink to the channel
	fa7_2.sources.r1.channels = c1
	fa7_2.sinks.k1.channel = c1
	-------------------
	:x

	***
	***  3 - Run the agent...
	***
    flume-ng agent --n fa7_2 --f /home/cloudera/fumeProblem7/flume_pb2.conf 
	
	***
	***  4 - confirm if logs are getting dumped to hdfs...
	***

	$ hdfs dfs -ls /user/cloudera/problem7/step2

	$ stop_logs